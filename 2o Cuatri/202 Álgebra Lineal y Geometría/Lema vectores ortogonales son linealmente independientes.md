
---
mathLink:
---
### Contenido Principal

**Fecha:** 2024-03-23, 18:03

```ad-lemma
Sean $x_1, \dots, x_n \in V - \{0\}$, donde $V$ es un [[Espacio vectorial euclídeo]] con el [[producto escalar]] $·$, [[Vectores ortogonales]] dos a dos, entonces $\{x_1, \dots, x_n\}$ es linealmente independiente ([[Independencia lineal]]).
```


```ad-proof
Sean $\alpha_1, \dots, \alpha_n \in \mathbb R$ tales que $\alpha_1 x_1 + \dots + \alpha_n x_n = 0$. Tenemos:
$$0 = 0 · x_i = (\alpha_1 v_1 + \dots + \alpha_n v_n) x_i = \alpha_i x_i · x_i = 0 \implies \alpha_i = 0, \quad \forall i.$$
Luego $\{x_1, \dots, x_n\}$ es linealmente independiente
```

**Tema:** [[Espacios vectoriales euclídeos]]
**Corolarios:** [[Método de Gram-Schmidt]]

---
### Anki

START
Básico
Anverso: Demostración de que sean $x_1, \dots, x_n \in V - \{0\}$, donde $V$ es un [[Espacio vectorial euclídeo]] con el [[producto escalar]] $·$, [[Vectores ortogonales]] dos a dos, entonces $\{x_1, \dots, x_n\}$ es linealmente independiente ([[Independencia lineal]]).
Reverso: Sean $\alpha_1, \dots, \alpha_n \in \mathbb R$ tales que $\alpha_1 x_1 + \dots + \alpha_n x_n = 0$. Tenemos:
$$0 = 0 · x_i = (\alpha_1 v_1 + \dots + \alpha_n v_n) x_i = \alpha_i x_i · x_i = 0 \implies \alpha_i = 0, \quad \forall i.$$
Luego $\{x_1, \dots, x_n\}$ es linealmente independiente
Tags: demostración ÁlgebraI
<!--ID: 1712235233638-->
END
